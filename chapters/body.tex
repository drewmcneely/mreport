\chapter{Introduction}

The goal set forth by this thesis seems ambitious: to introduce a completely new language of uncertainty and information that abstracts away measure theory, probability, etc. and is better primed for computation in estimation and stochastic control algorithms.
Research into this language is well underway in the mathematical community -- this thesis presents it in the context of stochastic dynamical systems, and discusses a methodology for formulating new stochastic estimation and control problems to be solved.

Much discussion in this thesis will be grounded in the classical Kalman filter, as it is a common estimator with which readers will more likely be familiar, and it serves as a good basic starting point for this methodology.
Indeed, the author did in fact get inspiration to study this topic after noticing a connection between propagation of uncertainty in the Kalman filter and the monadic bind operator in functional programming languages. This will be discussed later. While it may seem like we are ``reinventing the wheel'' in that this paper presents what seems to amount to just a new way to program Kalman filters, it must be stressed that the approach presented is hypothesized by the author to generalize to brand new estimators yet to be developed and offers a systematic way to derive them.

This approach to estimator derivation is more than just systematic; there is an aspect which is automatic, in that the user only derives simple elemental building blocks for a representation of uncertainty that they come up with, and more complicated algorithms automatically plumb these blocks together. In a way, this thesis shows that parts of a classical Kalman filter can be automatically derived by a computer.

\todo{expand the introduction.}

\section{Motivation}

\todo[inline]{Make a list with a breakdown of the Markov category axiom methods}

\subsection{Assumptions Made in the Kalman Filter}

\subsubsection{Definition of a Kalman Filter}

The Kalman filter is a commonly cited estimation routine for tracking uncertain dynamical systems.
The system in question is often modeled in discrete time, and carries a state that is unknown. 

A discrete dynamical system can be abstracted as a point $x\in X$ that evolves in a sequence $\{x_k\}_{k\in \naturals}$.
We call $x_k$ the state at time $k$, which lives in the state space $X$. For the Kalman filter, $X$ is a finite dimensional real-valued vector space $\reals^n$.
Measurements $z\in Z$ are then taken at each time step, where $Z$ is the measurement space. For the Kalman filter, $Z$ is usually taken to be the vector space $\reals^m$. For generality, we will still just refer to the spaces as $X$ and $Z$ respectively, as later on we will discuss generalizing these beyond vector spaces.

The mappings are linear with additive Gaussian noise. The dynamics and measurement models respectively are given by
\begin{equation}
	\label{kalman-filter-models}
	\begin{aligned}
		x &= Fx_- + \gaussian(0,Q)\\
		y &= Hx + \gaussian(0,R)
	\end{aligned}
\end{equation}
where $F:X\rightarrow X$, $H:X\rightarrow Z$, $Q\in \symmetric^X_+$, and $R\in\symmetric^Z_+$.
For simplicity, we omit the explicit references to time dependency and drop the subscripts for the time sequence.
Here we really only consider a single time step $k$ within the algorithm, as the algorithm is recursively looped and each step is implemented in the same way. If a variable has no subscript, it can be assumed that it draws from time step $k$. If it has the subscript ``$-$'', then it comes from the $k-1$ time step.

We switched the notion from additive noise to a formal sum. This is more a change in mindset and doesn't affect the outcome. In traditional texts, the equation $y = Hx + v,\ v\sim \gaussian(0,R)$ implies that the measurement model is an affine mapping, with an additive vector $v$ that gets drawn from a Gaussian distribution. Here, however, we add the distribution directly in a \emph{formal} sum in what we call a decorated linar map\cite{extended-gaussian}. The plus sign does not indicate that the distribution is literally added to the vector, which would be impossible, but simply that there is uncertainty attached to the model. 

The other thing to note is that $Q$ and $R$ are not strictly positive-definite, but they are relaxed to being positive semi-definite. This allows for the case where there actually is certainty, be it complete certainty or certainty within a subspace. This can also be extended to uninformative priors, again as in \cite{extended-gaussian}.

Our posterior knowledge of the state is characterized by a Gaussian uncertainty.
Thus at the current time step, the posterior knowledge from the prievious timestep is given as $\gaussian(\hat{x}_-, \hat{P}_-)$.
This is pushed through the dynamic model in Equation \ref{kalman-filter-model} to get the prior belief $\gaussian(\bar{x}, \bar{P})$ of the state at the current time step, with
\begin{align}
	\bar{x} = F\hat{x}_-\\
	\bar{P} = F\hat{P}_- F^T + Q
\end{align}
Further, this then gets propagated to our belief on where the measurement will fall, $\gaussian(\bar{z}, S)$ with
\begin{align}
	\bar{z} = H\bar{x}\\
	S = H\bar{P} H^T + R
\end{align}
our belief on where the measurement will fall, $\gaussian(\bar{z}, S)$ with

This next part we will present in a way that's slightly rearranged from common texts, but which sets the stage or further generalizing the filter.
In particular, typically a measurement error is defined as $\tilde{y} = z - \bar{z}$, but we define the following:

\begin{equation}
	K = \bar{P}H^T S^{-1}
\end{equation}

\begin{equation}
	\tilde{x} = \bar{x} - K\bar{z}
\end{equation}

We then get our posterior estimate

\begin{align}
	\hat{x} = Kz + \tilde{x} \\
	\hat{P} = (I-KH)\bar{P}
\end{align}

** Maybe something simpler? KF assumes white Gaussian noise. Is this assumption present in the framework you have in mind? Can you for instance handle the estimation problem (at least in principle) with colored noise? **

\section{Abstract Programming}

\begin{figure}[htb]
    \includegraphics[width=0.5\textwidth]{algorithm-inheritance}
	\caption{}
    \label{fig:algorithm-inheritance}
\end{figure}

\section{Looking at Markov Transition Kernels}

There is often some conflation between conditionals and transition kernels.
In a way, they are often considered to be developments from the basics of probability.
This stems from the fact that in traditional probability theory, the probability distribution or probability measure is the fundamental notion from which all other definitions and developments are derived.
Similar to how in categorical thinking, where the perspective is switched from sets being fundamental to functions being fundamental, we want to change lenses away from distributions and onto kernels as being the most elemental construction from which distributions, statistics, and algorithms are derived. 
Of course, it significantly helps us in our understanding if we already have some insight into a traditional measure-theoretic way of thinking about probability, but this is not totally necessary.
It more serves as a grounding point, similar to when learning category theory -- it helps greatly to already be familiar with sets+functions, vector spaces+linear maps, topoligical spaces+continuous maps, groups+group homomorphisms, and so on so that we have a \emph{context} for where categories are really useful as a language to describe stuff instead of only this abstract notion of arrows and objects and categories of categories.

Before giving a formal definition of categories, we should just mention for the familiarity of the reader that a category is made of arrows called \emph{morphisms} that are useful in describing mappings between spaces. In categorical probability, these morphisms can describe \emph{mappings that behave like Markov transition kernels}.

But what exactly is a transition kernel?
Intuition would say that it is a mapping between distributions, but there is a bit more nuance than that. ** Add some text to introduce these equations **

\begin{equation}
\label{traditional-gaussian-model}
\begin{gathered}
    y = Fx + w \\
    w \sim \gaussian(\bar{w}, R)
\end{gathered}
\end{equation}

\begin{equation}
    \begin{aligned}
	y = f(x,w)
    \end{aligned}
\end{equation}
\todo{Talk about how this has randomness pushback}
\todo[inline]{Talk about how the frequentist view of these kernels sees that w gets sampled in the instant that y gets evaluated, and acts as a modifier to Fx. We want to change this to a Bayesian view, where F evaluates by taking in an x and returning a distribution. A p(y|x) kind of thing. The problem is that bar notation, tilde notation, and distributions in the Bayesian context SUCK (** this is your personal view point; be more ``diplomatic''; explain why is that **). This is where the functors come in.}

\todo{List a bunch of variations on kernels, and discuss them.}

One minor change to our language that can have significant impact is in the recasting of equations into functions\todo{expand on this}.

\subsection{Recasting the Datatypes}
The trouble with random variables:
Random variables suck. Here's why...

Random variables are often pitched to the student (** why are you referring to ``students''? **) as variables that take on values (ie.\ real numbers) in a random fashion.
There is a frequentist sort of nature to this description, as if a random variable is a number that changes its value every time you look at it.

There is an alternative viewpoint: what is often called the Bayesian view of probability.
It states that probability (of an event) is simply a measure of our belief in a state, or more specifically the amount we believe that a state will fall into that event.
We wish to take this viewpoint and run with it, generalizing into many different ways of characterizing our belief or information on the state of a system.

Given a real finite dimensional vector space $X$, we will define for now\footnote{This and the treatment in \ref{sec:kernel-signature} looks like we're setting up $\gaussian$ as a functor for formulating $\gausscat$ as a Kleisli category. It's well conjectured that $\gausscat$ is not a Kleisli category. For demonstration purposes however, I'm setting it up like one here to introduce readers to the concept using familiar constructions. We will discuss decorated maps a-l\`a \cite{stein2022extended} later.} the collection of Gaussian distributions on $X$.
For the practical purposes of making datatypes, it's sufficient to define it through its parameterization of a mean and covariance as opposed to defining it as the actual collection of Gaussian probability measures.
Thus, we define $\gaussian$ as a type-level\footnote{Defined later in our discussion of functional programming} mapping on vector spaces:

The parameterization of our knowledge of the state lives in a separate space from the state itself.
While the system itself has a state $x\in X$, our knowledge of it, characterized by a Gaussian distribution, has a parameterization $(x,P)\in X\times \symmetric^X_+$.
We notate this space, the space of 


\begin{equation}
    \gaussian : X \mapsto \{(x,P) : x\in X, P \in \symmetric^X_+\}
\end{equation}

\section{The Signature of Kernels}
\label{sec:kernel-signature}

One confusing aspect of Markov transition kernels is their signature. 
Standard texts describe the a kernel as the following:

\todo{markov kernel definition}

The important bit is in the partial application: parameterizing $\kappa$ with $x$, the function $\kappa(\cdot, x)$ is a probability measure from $\mathcal{B} \rightarrow [0,1]$ and parameterizing with $B\in \mathcal{B}$, the function $\kappa(B,\cdot)$ is a \emph{mapping whose domain is $X$}.
This is important: $\kappa$ does not input values of distributions, but rather values of state.
This is evident in the confusing bar notation: $p(y|x)$ reads as ``$p$ of $y$ given $x$".
In other words, the transition kernel gives a distribution on $Y$ given a fixed value of $x\in X$.

Using Currying ie.\ partial application\todo{expand on this?}, we can rewrite this signature. 
Since $\giry Y$ is defined to be the collection of distributions on $Y$, then there is an equivalence between $\kappa : \mathcal{B} \times X \rightarrow [0,1]$ and $\kappa : X \rightarrow \giry Y$.

We can give the same treatment to Gaussian models of the form in Equation \ref{eq:traditional-gaussian-model} in Kalman filters, which are also just Markov kernels. The maps just happen to be linear and the distributions gaussian.
While we treat $x$ as a random variable in $y = Fx + w$, the $F$ does not take in random variables.
It takes plain old vectors.
We had to do the work of figuring out how to propagate covariance through $F$.
Further, \ref{eq:traditional-gaussian-model} injects its own distribution into the codomain through $w$.

\todo[inline]{Say something about frequentist statistics}

Using a similar approach to above, let's recast the signature into the new datatype.

\todo[inline]{Talk about how the kernel $\kappa$ has a signature $\mathcal{B}\times X \rightarrow [0,1]$, but we can equivalently formulate it as $\kappa : X \rightarrow \mathcal{P} Y$}

\section{Functional Programming}
\subsection{Higher Order Functions}

A powerful feature of the functional programming paradigm and the first class citizenship of functions is that 

\subsection{Higher Order Types and Type Functions}
\subsection{Typeclasses and Abstract Base Classes}

\chapter{Background}
\section{Category Theory}
\subsection{Categories}

A category formally is a collection of objects and morphisms that follow a composition law \cite{context}. \todo{Expand on this. Should I give an actual definition of an abstract category? I probably should}

While this definition is very abstract, it is useful in describing a lot of things \todo{find a better word} in mathematics.
Some of the most useful categories for application are \emph{concrete} categories, which practically are categories whose objects spaces with some form of structure and morphisms are structure preserving mappings between them.


\missingfigure{Make a diagram to represent a few objects/morphisms in $\Set$.}
\missingfigure{Make a diagram to represent a few objects/morphisms in $\FinVect$. Make it look congruent to $\Set$.}

An example is shown in $\Set$ and $\FinVect$.
The category $\Set$ has sets as its objects, and its morphisms are functions.
The category $\FinVect$ has as its objects finite dimensional vector spaces over the real numbers as their bed of scalars, and its morphisms are linear transformations\footnote{These transformations can be represented by a matrix, but only if a basis is provided for both domain and codomain. We should not automatically assume a vector space has a canonical basis that's best for the job!}.
Note that $\FinVect$ is just a subcategory\footnote{I won't define it, but I hope it's not hard to imagine what a subcategory is. Closure under composition is the main requirement.} of $\Set$. This is talked about in more detail in books.\todo{Specify}

This view is different from a set theoretic approach to fields in mathematics.
For instance, the set theoretic approach to linear algebra would define a vector space as a set with a certain algebraic structure, and a linear transformation as a function preserving that structure in a certain way.
A categorical approach would instead define the category of vector spaces as a collection of objects (the vector spaces) and of morphisms\footnote{and of functors. more on that later}, and would specify how morphisms behave in composition.
This approach is described as "context rich and content poor"\todo{cite youtube video}
\todo[inline]{Finish this paragraph. Element poor, but we can get around that, and the language is unified to describe similar phenomena in different fields, blah blah blah}

\todo[inline]{Talk about functional programming}
\todo[inline]{Talk about how Markov categories are cats with markov kernels}

\subsection{Functors}
\subsubsection{Example Functors}
\subsection{Monoidal Functors}
\subsection{Natural Transformations}
\subsection{Monads}
\subsection{Kleisli Categories}

\section{Markov Categories}

\subsection{Example: Set}
\subsection{Kleisli Categories}

\section{String Diagrams}

String diagrams are very similar to the signal flow diagrams or block diagrams found in control systems.
Others (\cite{baez2015control}, \cite{fong2016thesis}, \cite{fong2016dynamicalsystems}) have drawn the connections between string diagrams and various diagrams in systems engineering including block diagrams for dynamical systems.

There are often two interpretations in block diagrams:
In what I will call the temporal interpretation, the state of a diagram can be seen as changing over time, where the states are carried by the wires from block to block. The blocks represent state transformations, which are applied continuously to their inputs to generate changing outputs.
There may be blocks which carry their own internal state, such as integrators, that keep track of quantities over time to affect their output\todo{This sentence sucks.}

In what I'll call the signal flow interpretation, a time-varying signal is seen as a single entity, and the blocks represent signals in transformation space. This interpretation allows for a more functional analysis type approach to control design.

String diagrams look quite similar to block diagrams, but their interpretation is very different.
Blocks are still seen as transformations, but they then become the primary point of interest instead of the "signals" themselves.
The wires do not represent signals, but rather state spaces.
Whenever a wire splits, or disappears, or loops around, that becomes interpreted as a special transformation itself.
With this interpretation, a string diagram simply becomes a tool to draw out complicated compositions of transformations, or morphisms in a symmetric monoidal category.

\subsection{Explanation of String Diagrams}

\subsection{Translating String Diagrams into Kernel Compositions}
String diagrams allow us to write complicated equations with a single picture that can then be systematically translated back into equations for computation.
These pictures are often much clearer to interpret, and easier to memorize as they can be puzzle pieced together.
Interpreting them is straightforward: Take the example problem of finding the conditional of a kernel with respect to part of its output.
This problem statement carries with it the nuance of the complexity in finding conditionals, unlike the simple measure theoretic definition.

Given $f:A\rightarrow X\otimes Y$, find $f_X : X\otimes A \rightarrow Y$ such that the equation in Figure \ref{fig:conditional} holds.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.5\textwidth]{conditional}
	\caption{The string diagram equation for the definition of conditioning.}
	\label{fig:conditional}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.5\textwidth]{conditional-compositions}
	\caption{The conditional equation is read like so. This corresponds to Equation \ref{eq:conditional-compositions}.}
	\label{fig:conditional-compositions}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.5\textwidth]{conditional-parallel-compositions}
	\caption{The conditional equation can also be read this way. This corresponds to Equation \ref{eq:conditional-parallel-compositions}.}
	\label{fig:conditional-parallel-compositions}
\end{figure}

\begin{equation}
\label{eq:conditional-compositions}
f = (\counit_X \otimes f) \circ (\comul_X \otimes \id_A)
\circ (\id_X \otimes \counit_Y \otimes \id_A) \circ (f \otimes \id_A) \circ \comul_A
\end{equation}

\begin{equation}
\label{eq:conditional-parallel-compositions}
f = (\id_x \otimes f_x) \circ \left[\left(\comul_x \circ (\id_x\otimes \counit_Y) \circ f\right) \otimes \id_A\right] \circ \comul_A
\end{equation}

** Explain notation. Every operator you are using in these equations should be explained and formally introduced. **

\section{Bar Notation}
\subsection{Explanation of Bar Notation}
\subsection{Translating Bar Notation into String Diagrams}

\chapter{Common Representations of Information Recast into the Language of Markov Categories}
\section{Discrete Probability}
\section{Gaussian Probability}
\section{Gaussian Mixtures: A Composition of Discrete and Gaussian Probability}
\section{Unscented Transform}

\chapter{Programming with Markov Categories}
\section{Making Datatypes}
\subsection{Gaussian}
\subsection{Unscented}
\subsection{Gaussian Mixtures}

\section{Synthetic Algorithms Used in Estimation and Control}
\subsection{Filtering}
\subsection{History Space}

