\relax 
\@writefile{toc}{\contentsline {chapter}{Chapter 1.\hspace  *{1em}Introduction}{1}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{tdo}{\contentsline {todo}{write this better}{1}}
\@writefile{tdo}{\contentsline {todo}{expand the introduction.}{1}}
\@writefile{toc}{\contentsline {chapter}{Chapter 2.\hspace  *{1em}Motivation}{2}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{tdo}{\contentsline {todo}{Make a list with a breakdown of the markov category axiom methods}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Assumptions Made in the Kalman Filter}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Abstract Programming}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces }}{2}}
\newlabel{fig:algorithm-inheritance}{{2.1}{2}}
\@writefile{toc}{\contentsline {chapter}{Chapter 3.\hspace  *{1em}Looking at Markov Transition Kernels}{3}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\newlabel{traditional-gaussian-model}{{3.1}{4}}
\@writefile{tdo}{\contentsline {todo}{Talk about how this has randomness pushback}{4}}
\@writefile{tdo}{\contentsline {todo}{Talk about how the frequentist view of these kernels sees that w gets sampled in the instant that y gets evaluated, and acts as a modifier to Fx. We want to change this to a Bayesian view, where F evaluates by taking in an x and returning a distribution. A p(y|x) kind of thing. The problem is that bar notation, tilde notation, and distributions in the Bayesian context SUCK. This is where the functors come in.}{4}}
\@writefile{tdo}{\contentsline {todo}{List a bunch of variations on kernels, and discuss them.}{4}}
\@writefile{tdo}{\contentsline {todo}{expand on this}{4}}
\citation{stein2022extended}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Recasting the Datatypes}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}The Signature of Kernels}{6}}
\newlabel{sec:kernel-signature}{{3.2}{6}}
\@writefile{tdo}{\contentsline {todo}{markov kernel definition}{6}}
\@writefile{tdo}{\contentsline {todo}{expand on this?}{6}}
\@writefile{tdo}{\contentsline {todo}{Say something about frequentist statistics}{7}}
\@writefile{tdo}{\contentsline {todo}{Talk about how the kernel $\kappa $ has a signature $\EuScript  {B}\times X \rightarrow [0,1]$, but we can equivalently formulate it as $\kappa : X \rightarrow \EuScript  {P} Y$}{7}}
\@writefile{toc}{\contentsline {chapter}{Chapter 4.\hspace  *{1em}Functional Programming}{8}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Higher Order Functions}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Higher Order Types and Type Functions}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Typeclasses and Abstract Base Classes}{8}}
\citation{baez2015control}
\citation{fong2016thesis}
\citation{fong2016dynamicalsystems}
\@writefile{toc}{\contentsline {chapter}{Chapter 5.\hspace  *{1em}Background}{9}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Category Theory}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Categories}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Functors}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2.1}Example Functors}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Monoidal Functors}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}Natural Transformations}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.5}Monads}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.6}Kleisli Categories}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Markov Categories}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Example: Set}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Kleisli Categories}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}String Diagrams}{9}}
\@writefile{tdo}{\contentsline {todo}{This sentence sucks.}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Explanation of String Diagrams}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Translating String Diagrams into Kernel Compositions}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces The string diagram equation for the definition of conditioning.}}{11}}
\newlabel{fig:conditional}{{5.1}{11}}
\newlabel{eq:conditional-compositions}{{5.1}{11}}
\newlabel{eq:conditional-parallel-compositions}{{5.2}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces The conditional equation is read like so. This corresponds to Equation 5.1\hbox {}.}}{12}}
\newlabel{fig:conditional-compositions}{{5.2}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Bar Notation}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Explanation of Bar Notation}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Translating Bar Notation into String Diagrams}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces The conditional equation can also be read this way. This corresponds to Equation 5.2\hbox {}.}}{13}}
\newlabel{fig:conditional-parallel-compositions}{{5.3}{13}}
\@writefile{toc}{\contentsline {chapter}{Chapter 6.\hspace  *{1em}Common Representations of Information Recast into the Language of Markov Categoreis}{14}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Discrete Probability}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Gaussian Probability}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Gaussian Mixtures: A Composition of Discrete and Gaussian Probability}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Unscented Transform}{14}}
\@writefile{toc}{\contentsline {chapter}{Chapter 7.\hspace  *{1em}Programming with Markov Categories}{15}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Making Datatypes}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Gaussian}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Unscented}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.3}Gaussian Mixtures}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Synthetic Algorithms Used in Estimation and Control}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}Filtering}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.2}History Space}{15}}
\@setckpt{chapters/body}{
\setcounter{page}{16}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{7}
\setcounter{section}{2}
\setcounter{subsection}{2}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{regular@short}{0}
\setcounter{no@chapters}{0}
\setcounter{regular@short@col}{0}
\setcounter{parentequation}{0}
\setcounter{@todonotes@numberoftodonotes}{13}
\setcounter{thm}{0}
\setcounter{ax}{0}
\setcounter{defn}{0}
\setcounter{rem}{0}
}
